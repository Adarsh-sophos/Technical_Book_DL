\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Feedforward Neural Networks}{11}{chapter.4}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {xchapter}{Feedforward Neural Networks}{11}{chapter.4}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {xchapter}{Feedforward Neural Networks}{11}{chapter.4}}
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{sec:chapterFNN}{{4}{11}{Feedforward Neural Networks}{chapter.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{12}{section.4.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.2}FNN architecture}{13}{section.4.2}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Neural Network with $N+1$ layers ($N-1$ hidden layers). for simplicity of notations, the index referencing the training set has not been indicated. Shallow architectures use only one hidden layer. Deep learning amounts to take several hidden layers, usually containing the same number of hidden neurons. This number should be on the ballpark of the average of the number of input and output variables.}}{13}{figure.4.1}}
\newlabel{fig:1}{{4.1}{13}{Neural Network with $N+1$ layers ($N-1$ hidden layers). for simplicity of notations, the index referencing the training set has not been indicated. Shallow architectures use only one hidden layer. Deep learning amounts to take several hidden layers, usually containing the same number of hidden neurons. This number should be on the ballpark of the average of the number of input and output variables}{figure.4.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.3}Some notations}{14}{section.4.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.4}Weight averaging}{14}{section.4.4}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Weight averaging procedure.}}{15}{figure.4.2}}
\newlabel{fig:3}{{4.2}{15}{Weight averaging procedure}{figure.4.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.5}Activation function}{15}{section.4.5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}The sigmoid function}{15}{subsection.4.5.1}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces  the sigmoid function and its derivative.}}{16}{figure.4.3}}
\newlabel{fig:sigmoid}{{4.3}{16}{the sigmoid function and its derivative}{figure.4.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}The tanh function}{16}{subsection.4.5.2}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces  the tanh function and its derivative.}}{17}{figure.4.4}}
\newlabel{fig:tanh}{{4.4}{17}{the tanh function and its derivative}{figure.4.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}The ReLU function}{17}{subsection.4.5.3}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces  the ReLU function and its derivative.}}{18}{figure.4.5}}
\newlabel{fig:relu}{{4.5}{18}{the ReLU function and its derivative}{figure.4.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}The leaky-ReLU function}{18}{subsection.4.5.4}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces  the leaky-ReLU function and its derivative.}}{19}{figure.4.6}}
\newlabel{fig:lrelu}{{4.6}{19}{the leaky-ReLU function and its derivative}{figure.4.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.5}The ELU function}{19}{subsection.4.5.5}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces  the ELU function and its derivative.}}{20}{figure.4.7}}
\newlabel{fig:elu}{{4.7}{20}{the ELU function and its derivative}{figure.4.7}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.6}FNN layers}{20}{section.4.6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Input layer}{20}{subsection.4.6.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Fully connected layer}{21}{subsection.4.6.2}}
\newlabel{eq:Weightavg}{{4.18}{21}{Fully connected layer}{equation.4.6.18}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Output layer}{21}{subsection.4.6.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.7}Loss function}{21}{section.4.7}}
\newlabel{sec:FNNlossfunction}{{4.7}{21}{Loss function}{section.4.7}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.8}Regularization techniques}{22}{section.4.8}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.1}L2 regularization}{22}{subsection.4.8.1}}
\newlabel{eq:l2reg}{{4.26}{22}{L2 regularization}{equation.4.8.26}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.2}L1 regularization}{23}{subsection.4.8.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.3}Clipping}{24}{subsection.4.8.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.4}Dropout}{24}{subsection.4.8.4}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces The neural network of figure \ref  {fig:1} with dropout taken into account for both the hidden layers and the input. Usually, a different (lower) propability for turning off a neuron is adopted for the input thanthe one adopted for the hidden layers.}}{25}{figure.4.8}}
\newlabel{fig:2}{{4.8}{25}{The neural network of figure \ref {fig:1} with dropout taken into account for both the hidden layers and the input. Usually, a different (lower) propability for turning off a neuron is adopted for the input thanthe one adopted for the hidden layers}{figure.4.8}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.5}Batch Normalization}{25}{subsection.4.8.5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.9}Backpropagation}{27}{section.4.9}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.1}Backpropagate through Batch Normalization}{27}{subsection.4.9.1}}
\newlabel{sec:Backpropbatchnorm}{{4.9.1}{27}{Backpropagate through Batch Normalization}{subsection.4.9.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.2}error updates}{27}{subsection.4.9.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.3}Weight update}{28}{subsection.4.9.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.4}Coefficient update}{28}{subsection.4.9.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.10}Which data sample to use for gradient descent?}{29}{section.4.10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.10.1}Full-batch}{29}{subsection.4.10.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.10.2}Stochastic Gradient Descent (SGD)}{29}{subsection.4.10.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.10.3}Mini-batch}{29}{subsection.4.10.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.11}Gradient optimization techniques}{30}{section.4.11}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.11.1}Momentum}{30}{subsection.4.11.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.11.2}Nesterov accelerated gradient}{30}{subsection.4.11.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.11.3}Adagrad}{31}{subsection.4.11.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.11.4}RMSprop}{31}{subsection.4.11.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.11.5}Adadelta}{31}{subsection.4.11.5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.11.6}Adam}{32}{subsection.4.11.6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.12}Weight initialization}{32}{section.4.12}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{Appendices}{33}{equation.4.12.73}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.A}Backprop through the output layer}{33}{section.1.4.A}}
\newlabel{sec:appenbpoutput}{{4.A}{33}{Backprop through the output layer}{section.1.4.A}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.B}Backprop through hidden layers}{34}{section.1.4.B}}
\newlabel{sec:appenbplayers}{{4.B}{34}{Backprop through hidden layers}{section.1.4.B}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.C}Backprop through BatchNorm}{34}{section.1.4.C}}
\newlabel{sec:appenbatchnorm}{{4.C}{34}{Backprop through BatchNorm}{section.1.4.C}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.D}FNN ResNet (non standard presentation)}{35}{section.1.4.D}}
\newlabel{sec:ResnetFNN}{{4.D}{35}{FNN ResNet (non standard presentation)}{section.1.4.D}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces  Schematic representation of one FNN fully connected layer.}}{36}{figure.4.9}}
\newlabel{fig:fc_equiv}{{4.9}{36}{Schematic representation of one FNN fully connected layer}{figure.4.9}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces  Residual connection in a FNN.}}{36}{figure.4.10}}
\newlabel{fig:fc_resnet_2}{{4.10}{36}{Residual connection in a FNN}{figure.4.10}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.E}FNN ResNet (more standard presentation)}{38}{section.1.4.E}}
\newlabel{sec:ResnetFNN2}{{4.E}{38}{FNN ResNet (more standard presentation)}{section.1.4.E}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces  Residual connection in a FNN, trivial gradient flow through error rates.}}{38}{figure.4.11}}
\newlabel{fig:fc_resnet_3}{{4.11}{38}{Residual connection in a FNN, trivial gradient flow through error rates}{figure.4.11}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.F}Matrix formulation}{38}{section.1.4.F}}
\@setckpt{chapter1}{
\setcounter{page}{40}
\setcounter{equation}{97}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{1}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{11}
\setcounter{table}{0}
\setcounter{mtc}{4}
\setcounter{minitocdepth}{2}
\setcounter{ptc}{0}
\setcounter{parttocdepth}{2}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{parentequation}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{1}
\setcounter{bookmark@seq@number}{23}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{18}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextrayear}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{cbx@tempcnta}{0}
\setcounter{cbx@tempcntb}{15}
\setcounter{AlgoLine}{0}
\setcounter{algocfline}{0}
\setcounter{algocfproc}{0}
\setcounter{algocf}{0}
\setcounter{float@type}{8}
\setcounter{myalgo}{0}
\setcounter{subsubsubsection}{0}
\setcounter{@pps}{1}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{lips@count}{0}
\setcounter{minilofdepth}{2}
\setcounter{minilotdepth}{2}
\setcounter{partlofdepth}{2}
\setcounter{partlotdepth}{2}
\setcounter{sectlofdepth}{2}
\setcounter{sectlotdepth}{2}
\setcounter{section@level}{0}
}
